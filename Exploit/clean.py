import json
import logging
import os
import threading
import time
import configparser
from openai import OpenAI, APIError
from concurrent.futures import ThreadPoolExecutor

# Configuration loading
config = configparser.ConfigParser()
config.read('config.ini')
api_keys = config['API_KEYS']['Keys'].split(',')
file_path = config['DEFAULT']['FilePath']


crKey = 0
lock = threading.Lock()
results_list = []  # To collect all results

def get_client():
    with lock:
        if crKey < len(api_keys):
            return OpenAI(api_key=api_keys[crKey], base_url="https://api.deepseek.com/v1")
        else:
            logging.error("No valid API keys available. All API keys exhausted.")
            return None

def read(fp):
    try:
        with open(fp, 'r', encoding='utf-8') as f:
            data = json.load(f)
            return [{"title": item['title'], "role": "user", "content": item['content']}
                    for item in data if 'content' in item and item['content'].strip()]
    except FileNotFoundError:
        logging.error(f"File not found: {fp}")
        return []
    except json.JSONDecodeError:
        logging.error(f"JSON decode error in file: {fp}")
        return []

def update_api():
    with lock:
        global crKey
        crKey += 1
        if crKey < len(api_keys):
            logging.info(f"API key updated to new key: {api_keys[crKey]}")
            return True
        else:
            logging.error("All API keys exhausted.")
            return False

def backoff(retries):
    time.sleep(2 ** retries)

def call_api(ms):
    retries = 0
    while retries < 5:
        client = get_client()
        if not client:
            return None

        try:
            response = client.chat.completions.create(
                model="deepseek-coder",
                messages=[ms]
            )
            return {
                'title': ms['title'],
                'problem': ms['content'],
                'answer': [{'index': choice.index, 'content': choice.message.content} for choice in response.choices]
            }
        except APIError as e:
            if "Insufficient Quota" in str(e):
                logging.warning(f"Quota limit reached: {e}. Attempting to switch API key...")
                if not update_api():
                    return None
            else:
                logging.error(f"API error occurred: {e}")
                backoff(retries)
                retries += 1
        except Exception as e:
            logging.error(f"Unexpected error occurred: {e}")
            return None
    return None

def process_message(msg):
    result = call_api(msg)
    if result:
        with lock:
            results_list.append(result)  # Append result to the global list

def save_results():
    os.makedirs('output', exist_ok=True)
    with open('output/results.json', 'w', encoding='utf-8') as f:
        json.dump(results_list, f, indent=4)  # Save all results at once

if __name__ == "__main__":
    logging.basicConfig(level=logging.INFO)
    messages = read(file_path)
    if messages:
        logging.info(f"Processing {len(messages)} messages...")
        with ThreadPoolExecutor(max_workers=10) as executor:
            executor.map(process_message, messages)
        save_results()
        logging.info("Processing completed.")
    else:
        logging.error("No messages to process.")
