import json
import logging
from openai import OpenAI
from concurrent.futures import ThreadPoolExecutor, as_completed

api_key = "sk-1f1b4d0726fd4d04992bf2d3b4ef5087"
client = OpenAI(api_key=api_key, base_url="https://api.deepseek.com/v1")

def read(fp):
    try:
        with open(fp, 'r', encoding='utf-8') as f:
            data = json.load(f)
            return [{"title": item['title'], "role": "user", "content": item['content']}
                    for item in data if 'content' in item and item['content'].strip()]
    except FileNotFoundError:
        logging.error(f"Error: File '{fp}' not found.")
    except json.JSONDecodeError:
        logging.error(f"Error: Failed to decode JSON from file '{fp}'.")
    return []


def call_api(ms, retry_count=0):
    try:
        response = client.chat.completions.create(
            model="deepseek-coder",
            messages=[ms]
        )
        response_dict = {
            'title': ms['title'],
            'problem': ms['content'],
            'answer': [{'index': choice.index, 'content': choice.message.content} for choice in response.choices],
        }

        if any("I'm sorry" in choice.message.content for choice in response.choices) and retry_count < 1:
            print("Received an unsatisfactory response, retrying once...")
            return call_api(ms, retry_count + 1)

        print(json.dumps(response_dict, indent=4))

    except Exception as e:
        logging.error(f"An error occurred: {e}")


def process_messages(messages):
    with ThreadPoolExecutor(max_workers=min(10, len(messages))) as executor:
        futures = [executor.submit(call_api, message) for message in messages]
        for future in as_completed(futures):
            pass


if __name__ == "__main__":
    logging.basicConfig(level=logging.INFO)
    file_path = "../Exploit/data/51978-51976.json"
    messages = read(file_path)

    if messages:
        logging.info("--------------------------------------------")
        process_messages(messages)
    else:
        logging.info("No messages to process.")
